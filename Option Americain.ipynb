{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet 15 :  Options Américaines par régression\n",
    "Eleves : __Arthur MARON__ et __Thi Kim Anh TRAN__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ressources et libraries\n",
    "On importe différentes bibliothèques pour effectuer des calculs, des tracés et des générateurs de nombres aléatoires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librairies de calcul\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "#  Librairies de tracés\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Générateurs de nombres aléatoires\n",
    "from numpy.random import default_rng\n",
    "rng = default_rng(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On définit les paramètres de l'option américaine que l'on souhaite évaluer. Il suffira de changer le valeurs de ce dictionnaire pour étudier l'influence des paramètres sur le prix final. Définir une variable globale permettra de recuperer les paramètres de l'option dans différentes fonctions qui suivront."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Les paramètres pour notre option contienne au moins 250 jours de trading pour une échéance à 1 an.\n",
    "params = {\n",
    "        \"size_path\" : 250,\n",
    "        \"size_sample\" : int(1e6),\n",
    "        \"x0\" : 100,\n",
    "        \"r\" : 0.1,\n",
    "        \"sigma\" : 0.25,\n",
    "        \"K\" : 100,\n",
    "        \"T\" : 1}\n",
    "\n",
    "# On utilise on deuxième set de paramètres pour tester nos fonctions, moins couteuse en temps de calcul.\n",
    "param_debug = {\n",
    "        \"size_path\" : 10,\n",
    "        \"size_sample\" : int(1e3),\n",
    "        \"x0\" : 100,\n",
    "        \"r\" : 0.1,\n",
    "        \"sigma\" : 0.25,\n",
    "        \"K\" : 100,\n",
    "        \"T\" : 1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cas n°1 : un seul sous jacent pour l'évaluation de la première option de payoff : $ (K - X_{t}^1)_{+} $  \n",
    "On va définir une série de fonctions qui seront utilisées dans notre pricer américan dans le cas où notre payoff utilise un unique sous jacent. C'est donc un cas '1D'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Le payoff de l'option à évaluer\n",
    "On commence par définir la fonction de payoff de l'option à évaluer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def payoff_1(n, x): \n",
    "    N, _, _, r, _, K, T = params.values()\n",
    "    return np.exp(-r*n*T/N) * np.maximum(K-x, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Les bases de projection\n",
    "L'algorithme de Longstaff-Schwartz utilise une regression linéaire sur une base construire à partir du regresseur X. En changeant et utilisant différentes bases, on peut influencer la convergence du pricer dans le calcul du prix de l'option. On décide d'utiliser quatre bases différents : \n",
    "- Constante + 3 dimensions\n",
    "- Constante + 3 dimensions + payoff\n",
    "- Constante + 5 dimensions\n",
    "- Constante + 5 dimensions + payoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_1(x): \n",
    "    return np.array([np.ones_like(x),  x, x**2, x**3])\n",
    "\n",
    "def base_2(x): \n",
    "    K = params[\"K\"]\n",
    "    return np.array([np.ones_like(x), np.maximum(K-x,0), x, x**2, x**3])\n",
    "\n",
    "def base_3(x): \n",
    "    return np.array([np.ones_like(x),  x, x**2, x**3, x**4, x**5])\n",
    "\n",
    "def base_4(x): \n",
    "    K = params[\"K\"]\n",
    "    return np.array([np.ones_like(x), np.maximum(K-x,0), x, x**2, x**3, x**4, x**5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## La regression linéaire \n",
    "On implémente les fonction de calcul pour la regression linéaire. La première fonction calcul les paramètres thetas du modèle linéaire, et la deuxième effectue la prédiction linéaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_ols(payoff, X, base = base_1):\n",
    "    norm = (base(X) @ base(X).T)    \n",
    "    try : \n",
    "        return np.linalg.inv(norm) @ (base(X) @ payoff)\n",
    "    except:\n",
    "        return np.linalg.pinv(norm) @ (base(X) @ payoff)\n",
    "    \n",
    "def predict_ols(X, theta, base = base_1): \n",
    "    return np.dot(theta, base(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation des trajectoires\n",
    "On doit maintenant programmer un simulateur de trajectoires pour un mouvement brownien géometrique. On se place dans le cas où le sous-jacent a une tendance égale au taux sans risque - cad le cas risque neutre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simu_paths(size_path:int, size_sample:int, x0:float, r:float, sigma:float, K:float, T:float, \n",
    "               rndm = rng, payoff_function = payoff_1): \n",
    "    \n",
    "    # Simulation des trajectoires\n",
    "    h = T/size_path\n",
    "    accr = np.sqrt(h) * rndm.standard_normal(size=(size_path, size_sample))\n",
    "    sample = np.zeros(shape=(size_path+1, size_sample))\n",
    "    sample[0] = x0\n",
    "    for n in range(1, size_path+1):\n",
    "        sample[n] = sample[n-1] * np.exp((r - 0.5 * sigma**2)*h + sigma*accr[n-1])\n",
    "        \n",
    "    # Simulation des cashflows\n",
    "    cashflow = np.empty_like(sample)\n",
    "    for n in range(0, size_path+1):\n",
    "        cashflow[n] = payoff_function(n,sample[n])\n",
    "    \n",
    "    return sample, cashflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "\"\"\"_, _ = simu_paths(**param_debug, rndm = default_rng(1234), payoff_function = payoff_1)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution de l'algorithme de Longstaff-Schwartz\n",
    "On code maintenant l'algorithme de LS qui effecture une backpropagation par regression linéaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def longstaff_schwartz(sample, cashflow, base = base_1) :\n",
    "    # Récuperation de la taille de l'échantillon\n",
    "    size_path, size_sample = sample.shape[0]-1, sample.shape[1]\n",
    "\n",
    "    # Nombre de bases pour la projection ols\n",
    "    m = base(sample[0]).shape[0]   \n",
    "\n",
    "    # Initialisation des paramètres de la regression linéaire\n",
    "    thetas = np.zeros((size_path, m))     \n",
    "\n",
    "    # Initialisation des temps d'arrets et payoffs optimaux\n",
    "    optimal_stop = size_path * np.ones(size_sample, dtype=int)\n",
    "    optimal_payoff = cashflow[size_path].copy()\n",
    "        \n",
    "    # Algorithme récusif backward\n",
    "    for n in reversed(range(1, size_path)):\n",
    "        thetas[n] = reg_ols(optimal_payoff, sample[n], base)\n",
    "        is_optimal_n = cashflow[n] >= predict_ols(sample[n], thetas[n], base)    \n",
    "        optimal_stop[is_optimal_n] = n \n",
    "        optimal_payoff[is_optimal_n] = cashflow[n, is_optimal_n].copy()\n",
    "    \n",
    "    return optimal_payoff, thetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "\"\"\"xx, zz = simu_paths(**param_debug)\n",
    "_ = longstaff_schwartz(xx, zz, base = base_2)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On utilise un l'algorithme de Monte-Carlo pour trouver le prix final de l'option. En effet, l'algorthme de LS permet d'obtenir un échantillon de prix discounté au temps 0 pour chaque trajectoire simulée. On utilise cet échantillon pour trouver le prix par Monte Carlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monte_carlo(sample, proba = 0.95):\n",
    "    mean = np.mean(sample)\n",
    "    var = np.var(sample, ddof=1)\n",
    "    alpha = 1 - proba \n",
    "    quantile = stats.norm.ppf(1 - alpha/2)  \n",
    "    ci_size = quantile * np.sqrt(var / sample.size)\n",
    "    result = { 'mean': mean, 'var': var, \n",
    "               'lower': mean - ci_size, \n",
    "               'upper': mean + ci_size }\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalement, on implémente une fonction générale qui coordonne l'ensemble des fonctions précédantes pour simuler les trajectoires, lancer Lonstaff-Schwartz, et donner un prix par Monte-Carlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def us_pricer(size_path:int, size_sample:int, x0:float, r:float, sigma:float, K:float, T:float, \n",
    "                    rndm = rng, payoff_function = payoff_1, base = base_1, plot:bool=False) :\n",
    "       \n",
    "    # Simulation des trajectoires et des cashflows\n",
    "    X, Z = simu_paths(size_path, size_sample, x0, r, sigma, K, T, rndm, payoff_function)\n",
    "       \n",
    "    # Lancement de l'algorithme de LS\n",
    "    opt_payoff, thetas = longstaff_schwartz(X, Z, base)\n",
    "    \n",
    "    # Récuperation du prix par Monte Carlo\n",
    "    price = monte_carlo(opt_payoff)\n",
    "    \n",
    "    # Tracé des courbes\n",
    "    if plot :\n",
    "        x_tmp = np.linspace(int(0.8*K), int(1.2*K), 1000)\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.plot(x_tmp, payoff_function(size_path, x_tmp))\n",
    "        for n in np.linspace(1, size_path-1, 10, dtype=int) :\n",
    "            ax.plot(x_tmp, np.maximum(payoff_function(n, x_tmp), predict_ols(x_tmp, thetas[n], base)), label=fr\"t={n}\")\n",
    "            ax.set_title(f\"Les fonctions valeurs approchées.\\nBase : {base.__name__}\\nPrix : {price['mean']:.3f}\")\n",
    "            ax.legend()\n",
    "        ax.grid()\n",
    "\n",
    "    # Determination du prix par Monte Carlo\n",
    "    return price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "\"\"\"us_pricer(**param_debug, rndm = default_rng(1234) , payoff_function = payoff_1, base = base_2, plot = True)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation de la première option de payoff : $ (K - X_{t}^1)_{+} $  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bases = [base_1, base_2, base_3, base_4]\n",
    "prices = {i.__name__ : None for i in bases}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for base in bases :\n",
    "    prices[f\"{base.__name__}\"] = us_pricer(**params, rndm = default_rng(1234), \n",
    "                                           payoff_function = payoff_1, base = base, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "\"\"\"prices\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_res(prices:dict) :     \n",
    "    # Limites du graphique\n",
    "    tmp = list(prices.values())[0]\n",
    "    tmp = tmp[\"mean\"] - tmp[\"lower\"]\n",
    "    low = min([itm[\"lower\"] - tmp for itm in prices.values()])\n",
    "    high = max([itm[\"upper\"] + tmp for itm in prices.values()])\n",
    "    plt.ylim([low, high] )\n",
    "    \n",
    "    # Affichage des prix et des incertitudes\n",
    "    plt.title(\"Comparaison des prix du pricer US selon les bases utilisées\")\n",
    "    plt.bar(prices.keys(), [itm[\"mean\"] for itm in prices.values()], color=\"grey\")\n",
    "    plt.errorbar(prices.keys(), [itm[\"mean\"] for itm in prices.values()], \n",
    "                 yerr = [itm[\"mean\"]-itm[\"lower\"] for itm in prices.values()] ,\n",
    "                 fmt = 'none', capsize = 15, ecolor = 'red', elinewidth = 2, capthick = 2)\n",
    "    \n",
    "    # Affichage du texte\n",
    "    for i, price in enumerate(prices.values()) :\n",
    "        p, e = price[\"mean\"], price[\"mean\"] - price[\"lower\"]\n",
    "        plt.text(i, p, f\"{p:.3f}\", ha=\"right\", fontsize=16.5)\n",
    "        plt.text(i, p+e, f\"±{e:.3f}\", ha=\"center\", fontsize=15, color=\"red\")\n",
    "    \n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_res(prices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Commentaires :__ Il y a deux regroupements distincts dans les prix : les bases qui ont un payoff et celles qui n'en ont pas. Les bases avec un payoff ont tendance à donner des prix Monte Carlo plus élevés que celles sans. Il est important de noter que, selon la théorie de Longstaff-Schwartz, le prix obtenu par régression linéaire est généralement inférieur au prix réel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etude des performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit us_pricer(**param_debug, rndm = default_rng(1234), payoff_function = payoff_1, base = base_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Commentaires:__ On observe que le pricer met un temps de l'ordre de la milliseconde pour N = 10, ce qui correspond au nombre de pas utilisé pour l'option beermudéenne en cours de deuxième semestre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit us_pricer(**params, rndm = default_rng(1234), payoff_function = payoff_1, base = base_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Commentaires:__ Quand on augmente le nombre de pas pour se rapprocher d'une option américaine (on a pris N = 250 afin d'avoir au moins un point par jour de trading pour une option à échéance 1 an), le temps d'execution augmente considéreblement et passe à l'ordre de grandeur de la minute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cas n°2 : plusieurs sous jacents pour l'évaluation de la deuxième option de payoff : $ (K - \\sqrt{X_{t}^1 X_{t}^2})_{+} $ \n",
    "On va redéfinir une série de fonctions qui seront utilisées dans notre pricer américan dans le cas où notre payoff utilise plusieurs sous jacents. C'est donc un cas multidimensionnel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On définit les paramètres de l'option dont on va évaluer le prix. Cette fois il faut définir deux ......"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params2 = {\"size_path\":250, \n",
    "            \"size_sample\":int(1e6), \n",
    "            \n",
    "            # Paramètres du sous jacent 1\n",
    "            \"x0_1\":110,             \n",
    "            \"sigma_1\":0.45, \n",
    "           \n",
    "           # Paramètres du sous jacent 2\n",
    "            \"x0_2\":90, \n",
    "            \"sigma_2\":0.10,\n",
    "\n",
    "            \"r\":0.1,\n",
    "            \"K\":100, \n",
    "            \"T\":1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params2_debug = {\"size_path\":10, \n",
    "                \"size_sample\":int(1e3), \n",
    "\n",
    "                # Paramètres du sous jacent 1\n",
    "                \"x0_1\":110,             \n",
    "                \"sigma_1\":0.45, \n",
    "\n",
    "               # Paramètres du sous jacent 2\n",
    "                \"x0_2\":90, \n",
    "                \"sigma_2\":0.10,\n",
    "\n",
    "                \"r\":0.1,\n",
    "                \"K\":100, \n",
    "                \"T\":1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On doit redéfinir quelques fonctions en 2D."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Le payoff de l'option à évaluer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def payoff_2(n, X): \n",
    "    N, _, _, _, _, _, r, K, T = params2.values()\n",
    "    return np.exp(-r * n * T/N) * np.maximum(K - np.sqrt(X[0] * X[1]), 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Les bases de projection\n",
    "\n",
    "On décide que les bases de projections s'occupent de la décomposition des dimensions. Ainsi, on n'a pas à changer certaines fonctions, mais seulement les bases qui doivent être renseignée à la main de toute facon. Ici, on teste plusieurs approches : - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_5(X): \n",
    "    x, y = X[0], X[1]\n",
    "    return np.array([np.ones_like(x),  x*y, (x*y)**2, (x*y)**3])\n",
    "\n",
    "def base_6(X): \n",
    "    x, y, K = X[0], X[1], params2[\"K\"]\n",
    "    return np.array([np.ones_like(x), np.maximum(K - np.sqrt(x * y), 0), x*y, (x*y)**2, (x*y)**3 ])\n",
    "\n",
    "def base_7(X): \n",
    "    x, y = X[0], X[1]\n",
    "    return np.array([np.ones_like(x),  x, x**2, x**3, y, y**2, y**3])\n",
    "\n",
    "def base_8(X): \n",
    "    x, y, K = X[0], X[1], params2[\"K\"]\n",
    "    return np.array([np.ones_like(x),  np.maximum(K - np.sqrt(x * y), 0), x, x**2, x**3, y, y**2, y**3])\n",
    "\n",
    "def base_9(X): \n",
    "    x, y, K = X[0], X[1], params2[\"K\"]\n",
    "    return np.array([np.ones_like(x), np.maximum(K - np.sqrt(x * y), 0), (x*y)**0.5, (x*y), (x*y)**2 ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation des trajectoires en 2D\n",
    "La fonction de simulation doit ....\n",
    "Si on voulait avoir plus de 2 trajectoires, il faudrait ..... matrice de corrélation....."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simu_paths_2d(size_path:int, size_sample:int, \n",
    "                x0_1:float, sigma_1:float, \n",
    "                x0_2:float, sigma_2:float,  \n",
    "                r:float, K:float, T:float, correlation:float, \n",
    "                rndm = rng, payoff_function = payoff_2):\n",
    "    \n",
    "    # Simulation des trajectoires\n",
    "    h = T / size_path\n",
    "    dW = np.sqrt(h) * rndm.standard_normal((2, size_path, size_sample))\n",
    "    dB = dW.copy()\n",
    "    dB[1] = correlation * dW[0] + np.sqrt(1-correlation**2) * dW[1]\n",
    "    sample = np.zeros((2, size_path+1, size_sample))\n",
    "    sample[0][0], sample[1][0] = x0_1, x0_2\n",
    "    \n",
    "    for n in range(1, size_path+1):\n",
    "        sample[0][n] = sample[0][n-1] * np.exp((r - 0.5 * sigma_1**2)*h + sigma_1*dB[0][n-1])\n",
    "        sample[1][n] = sample[1][n-1] * np.exp((r - 0.5 * sigma_2**2)*h + sigma_2*dB[1][n-1])\n",
    "    \n",
    "    # Simulation des cashflows\n",
    "    cashflow = np.empty((size_path+1, size_sample))\n",
    "    for n in range(0, size_path+1):\n",
    "        cashflow[n] = payoff_function(n, sample[:, n, :] ) # [0][n], sample[1][n])\n",
    "    \n",
    "    return sample, cashflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "\"\"\"tmp, cs = simu_paths_2d(**params2_debug, correlation = 0.8, rndm = default_rng(1234))\n",
    "tmp[:, 1, :]\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On teste notre fonction pour le mouvement brownine gémoetrique à dimension 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_trajectoires(parametres, correlation = 0.5, **sample) :\n",
    "    times = np.arange(parametres[\"size_path\"]+1)*(parametres[\"T\"] / parametres[\"size_path\"])\n",
    "    plotted = False\n",
    "    \n",
    "    # Cas où on a renseigné des trajectoires et cashflow. Cela évite de re-simuler et sera utile pour size_path grand.\n",
    "    for item, obj in sample.items():\n",
    "        if item == \"trajectoire\" :\n",
    "            X = obj\n",
    "        if item == \"cashflow\":\n",
    "            cs = obj\n",
    "        plotted = True\n",
    "    \n",
    "    # Cas où on veut les simuler pour les afficher.\n",
    "    if not plotted :\n",
    "        X, cs = simu_paths_2d(**params2_debug, correlation = correlation, rndm = default_rng(1234))\n",
    "    \n",
    "    plt.plot(times, X[0,:,0], color='C0', label='X1')\n",
    "    plt.plot(times, X[1,:,0], color='C1', label='X2')\n",
    "    plt.plot(times, cs[:,0], color='C2', label='cashflow')\n",
    "    plt.title(\"Simulation 2D d'un MBG\") ; plt.legend() ; plt.grid() ; plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_trajectoires(params2_debug)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algortigme de Longstaff Schwartz\n",
    "On doit changer la fonction qui execute l'algortihme pour qu'elle prenne en compte la dimension supplémentaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def longstaff_schwartz_multi_d(sample, cashflow, base = base_5) :\n",
    "    # Taille de l'échantillon\n",
    "    size_path, size_sample =  sample[0,1:,:].shape\n",
    "    \n",
    "    # Nombre de bases pour la projection ols\n",
    "    m = base(sample[:, 0, :]).shape[0]   \n",
    "    \n",
    "    # Initialisation des paramètres de la regression linéaire\n",
    "    thetas = np.zeros((size_path, m))            \n",
    "    \n",
    "    # Initialisation des temps d'arrets et payoffs optimaux\n",
    "    optimal_stop = size_path * np.ones(size_sample, dtype=int)\n",
    "    optimal_payoff = cashflow[size_path].copy()\n",
    "        \n",
    "    # Algorithme récusif backward\n",
    "    for n in reversed(range(1, size_path)):\n",
    "        thetas[n] = reg_ols(optimal_payoff, sample[:, n, :], base)\n",
    "        is_optimal_n = cashflow[n] >= predict_ols(sample[:, n, :], thetas[n], base)    \n",
    "        optimal_stop[is_optimal_n] = n \n",
    "        optimal_payoff[is_optimal_n] = cashflow[n, is_optimal_n].copy()\n",
    "        \n",
    "    return optimal_payoff, thetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test\n",
    "\"\"\"xx, zz = simu_paths_2d(**params2_debug, correlation = 0.75)\n",
    "plot_trajectoires(params2_debug, 0.75, trajectoire = xx, cashflow = zz)\n",
    "opt_p, the = longstaff_schwartz_multi_d(xx, zz)\n",
    "opt_p[:10]\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant, on réécrit également la fonction de pricer pour deux sous-jacents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def us_pricer_2d(size_path:int, size_sample:int, \n",
    "                x0_1:float, sigma_1:float, x0_2:float, sigma_2:float,  \n",
    "                r:float, K:float, T:float, correlation:float=0.5,\n",
    "                rndm = rng, payoff_function = payoff_2, base = base_6, plot:bool=False) :\n",
    "       \n",
    "    # Simulation des trajectoires et des cashflows     \n",
    "    X, Z = simu_paths_2d(size_path, size_sample, \n",
    "                 x0_1, sigma_1, x0_2, sigma_2, r, K, T, correlation = correlation, \n",
    "                 rndm = rndm, payoff_function = payoff_function)\n",
    "    \n",
    "    # Lancement de l'algorithme de LS\n",
    "    opt_payoff, thetas = longstaff_schwartz_multi_d(X, Z, base)\n",
    "    \n",
    "    # Determination du prix par Monte Carlo\n",
    "    price = monte_carlo(opt_payoff)\n",
    "    \n",
    "    # Tracé des courbes 3D\n",
    "    if plot :\n",
    "        fig, ax = plt.figure(), plt.axes(projection='3d')\n",
    "        M = 10 # Résolution de l'affichage 3D\n",
    "        x1_tmp = np.linspace(90, 130, M)\n",
    "        x2_tmp = np.linspace(75, 140, M)\n",
    "        sample_tmp = np.array([x1_tmp, x2_tmp])#.reshape((2, 1, 1000))   \n",
    "        \n",
    "        def plot_3d(t, c) :    \n",
    "            payoff_t = np.zeros((M, M))\n",
    "            for i, x1 in enumerate(x1_tmp) :\n",
    "                for j, x2 in enumerate(x2_tmp) :\n",
    "                    payoff_t[i, j] = payoff_function(t, np.array([x1, x2]))\n",
    "            ax.plot_wireframe(x1_tmp, x2_tmp, payoff_t, label = f\"t={t}\", color=f\"C{c}\", alpha=0.5)\n",
    "            ax.legend()\n",
    "            \"\"\" Autre version 3D\n",
    "            #ax.contour3D(x1_tmp, x2_tmp, payoff_t, 50)\n",
    "            c1 = ax.plot_surface(x1_tmp, x2_tmp, payoff_t, rstride=1, cstride=1, cmap='viridis', \n",
    "                                 edgecolor='none', linewidths=0.2, label = f\"t={t}\")\n",
    "            c1._facecolors2d=c1._facecolors3d\n",
    "            c1._edgecolors2d=c1._edgecolors3d\n",
    "            \"\"\"\n",
    "        for c, n in enumerate(np.linspace(1, size_path-1, 3, dtype=int)) :\n",
    "            plot_3d(n, c)\n",
    "        ax.set_title(f\"Les fonctions valeurs approchées.\\nBase : {base.__name__}\\nPrix : {price['mean']:.3f}\")\n",
    "        plt.show()\n",
    "\n",
    "    return price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "\"\"\"us_pricer_2d(**params2_debug, correlation = 0.5, rndm = default_rng(1234), \n",
    "             payoff_function = payoff_2, base = base_6, plot = True)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation de la seconde option de payoff : $ (K - \\sqrt{X_{t}^1 X_{t}^2})_{+} $ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme pour la première option, on va évaluer l'option en utilisant plusieurs bases de proejction OLS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bases_2 = [base_5, base_6, base_7, base_8, base_9]\n",
    "prices_2 = {i.__name__ : None for i in bases_2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for base in bases_2 :\n",
    "    prices_2[f\"{base.__name__}\"] = us_pricer_2d(**params2, correlation = 0.55, \n",
    "                                              rndm = default_rng(1234) , payoff_function = payoff_2, base = base, plot = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On compare les prix finaux calculés par Monte Carlo selon les différents bases utilisées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_res(prices_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Commentaires:__ On observe une plus grande différence entre les prix calculés pour les différentes bases, et notamment une différence important lorsque l'on ajoute/retire le payoff dans la base de projection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etude des performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit us_pricer_2d(**params2, correlation = 0.5, rndm = default_rng(1234), payoff_function = payoff_2, base = base_6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Commentaires:__ On que l'ordre de grandeur de la minute est aussi présent dans le cas de la deuxième option. Ce temps d'execution relativement long par rapport à nos habitudes d'instantanéité n'est tout de même pas inhabituel dans le monde de la finance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etude numérique sur le prix du delta\n",
    "Le but de cette section est d'utiliser les fonctionnalité de calcul de gradien automatique afin de trouver le delta de l'option à évaluer. On a essayer plusieurs approches, mais celle qui semble la plus polyvalente necessite pytorch. En effet, jax n'est pas disponible sur windows, et autograd (ancienne version de jax) fonctionne mal avec la modification d'arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On initialise de nouveaux paramètres pour l'option 1 à évaluer et dont on voudra calculer le delta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_grad = {\n",
    "        \"size_path\" : 10, \n",
    "        \"size_sample\" : int(10e3),\n",
    "        \"r\" : torch.tensor([0.1], requires_grad=True), \n",
    "        \"sigma\" : torch.tensor([0.25], requires_grad=True), \n",
    "        \"K\" : torch.tensor([100.0], requires_grad=True), \n",
    "        \"T\" : torch.tensor([1.0], requires_grad=True) }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va désormais ré-écrire nos fonctions à l'aide du module pytorch, en excluant numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def payoff_1_torch(n, x): \n",
    "    N, _, r, _, K, T = params_grad.values()\n",
    "    return torch.exp(-r*n*T/N) * torch.maximum(K-x, torch.tensor([0.0], requires_grad=True) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "\"\"\"payoff_1_torch(0, 98.)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bases de projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_10(x): \n",
    "    return torch.stack((torch.ones_like(x),  x, x**2, x**3))\n",
    "\n",
    "def base_11(x): \n",
    "    K = params_grad[\"K\"]\n",
    "    return torch.stack([torch.ones_like(x), torch.maximum(K-x, torch.tensor([0.0])), x, x**2, x**3])\n",
    "\n",
    "def base_12(x): \n",
    "    return torch.stack([torch.ones_like(x),  x, x**2, x**3, x**4, x**5])\n",
    "\n",
    "def base_13(x): \n",
    "    K = params_grad[\"K\"]\n",
    "    return torch.stack([torch.ones_like(x), torch.maximum(K-x, torch.tensor([0.0])), x, x**2, x**3, x**4, x**5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test\n",
    "\"\"\"tmp = torch.tensor([98.2, 99.99])\n",
    "base_11(tmp)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fonction de regression OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_ols_torch(payoff, X, base = base_10):\n",
    "    norm = (base(X) @ torch.transpose(base(X), 0, 1) )     \n",
    "    try : \n",
    "        return torch.linalg.inv(norm) @ (base(X) @ payoff)\n",
    "    except:\n",
    "        return torch.linalg.pinv(norm) @ (base(X) @ payoff)\n",
    "    \n",
    "def predict_ols_torch(X, theta, base = base_10): \n",
    "    return torch.matmul(theta, base(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation des trajectoires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simu_paths_torch(x0, rndm = rng, payoff_function = payoff_1_torch): \n",
    "    \n",
    "    # Récuperation des paramètres pour l'option en grad\n",
    "    size_path, size_sample, r, sigma, K, T = params_grad.values()\n",
    "    h = T/size_path\n",
    "    \n",
    "    # Simulation des trajectoires individuellement\n",
    "    tmp = rndm.standard_normal(size=(size_path, size_sample))\n",
    "    accr = torch.sqrt(h) * torch.from_numpy(tmp)    \n",
    "    \n",
    "    samples = list(torch.full((1, size_sample), x0.item(), requires_grad=True) )    \n",
    "    for n in range(1, size_path+1):\n",
    "        tmp1, tmp2 = samples[-1].clone(), accr[n-1].clone()\n",
    "        samples.append(tmp1 * torch.exp((r - 0.5 * sigma**2) * h + sigma * tmp2 ))     \n",
    "    sample = torch.stack(samples)\n",
    "    #print(\"sample\", sample)\n",
    "    \n",
    "    # Simulation des cashflows individuellement\n",
    "    cashflows = [payoff_function(0, sample[0].clone())]     \n",
    "    for n in range(1, size_path+1):\n",
    "        cashflows.append(payoff_function(n, sample[n].clone()))\n",
    "    cashflow =  torch.stack(cashflows)\n",
    "    #print(\"cashflows\", cashflow)\n",
    "    \n",
    "    # Retour\n",
    "    return sample, cashflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = torch.tensor([100.0], requires_grad = True)\n",
    "_,_ = simu_paths_torch(xx, rndm = default_rng(1234), payoff_function = payoff_1_torch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Longstaff-Schwartz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def longstaff_schwartz_torch(sample, cashflow, base = base_10) :\n",
    "    # Récuperation de la taille de l'échantillon\n",
    "    size_path, size_sample = sample.shape[0] - 1, sample.shape[1]\n",
    "    \n",
    "    # Nombre de bases pour la projection ols ===============================================\n",
    "    m = base(sample[0]).shape[0]      \n",
    "    \n",
    "    # Initialisation des temps d'arrets et payoffs optimaux ==================================\n",
    "    optimal_stop = size_path * torch.ones(size_sample, requires_grad=True)\n",
    "    optimal_payoff = cashflow[size_path].clone()\n",
    "        \n",
    "    #Calcul des thetas =========================================================\n",
    "    thetas = list(torch.full((1, m), 0.0, requires_grad=True) )\n",
    "    for n in reversed(range(1, size_path)):\n",
    "        thetas.append(reg_ols_torch(optimal_payoff, sample[n].clone(), base))\n",
    "    theta = torch.stack(thetas)\n",
    "    #print(\"theta : \", theta)\n",
    "    \n",
    "    # Algorithme récusif backward ========================================================\n",
    "    for n in reversed(range(1, size_path)):\n",
    "        sample_n, theta_n = sample[n].clone(), theta[n].clone()\n",
    "        pred = predict_ols_torch(sample_n, theta_n, base)\n",
    "        is_optimal_n = cashflow[n].clone() >= pred\n",
    "        \n",
    "        optimal_stop[is_optimal_n] = n \n",
    "        #print(\"optimal_stop\", optimal_stop, '\\n', '-' * 50)\n",
    "        \n",
    "        optimal_payoff[is_optimal_n] = cashflow[n, is_optimal_n].clone()\n",
    "        #print(\"optimal_payoff\", optimal_payoff, '\\n', '_' * 50)\n",
    "    \n",
    "    opt_out = optimal_payoff.clone().detach().requires_grad_(True)\n",
    "    #return opt_out, theta    \n",
    "    return optimal_payoff, theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vv = torch.tensor([100.0], requires_grad = True)\n",
    "xx, zz = simu_paths_torch(vv, rndm = default_rng(1234))\n",
    "#print(xx)\n",
    "p, t = longstaff_schwartz_torch(xx, zz, base = base_10)\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Le pricer d'option américaine\n",
    "Cette fois on fait en sorte qu'il ne dépende que de x0 l'utilisation du gradien."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def us_pricer_raw(x0, rndm = rng, payoff_function = payoff_1_torch, base = base_10) :\n",
    "    \n",
    "    # Récuperation des paramètres de l'option\n",
    "    #size_path, size_sample, r, sigma, K, T = params_grad.values()\n",
    "    \n",
    "    # Simulation\n",
    "    X, Z = simu_paths_torch(x0, rndm, payoff_function)\n",
    "    print(\"X\", X)\n",
    "    \n",
    "    # Lonstaff Schwartz\n",
    "    opt_payoff, _ = longstaff_schwartz_torch(X, Z, base)\n",
    "    \n",
    "    # Return les payoff optimaux\n",
    "    return opt_payoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test\n",
    "vv = torch.tensor([100.0], requires_grad = True)\n",
    "us_pricer_raw(vv, rndm = default_rng(1234), payoff_function = payoff_1_torch, base = base_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def price_mc(x):\n",
    "    out_sample = us_pricer_raw(x, default_rng(1234), payoff_1_torch, base_10)    \n",
    "    return torch.mean(out_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "price_mc(torch.tensor([100.]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Différentiation automatique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Condition initiale en float\n",
    "x0 = 109.2\n",
    "\n",
    "# Condition initiale en pytorch\n",
    "x0_torch = torch.tensor([x0], requires_grad = True)\n",
    "print(\"x0_torch.requires_grad :\", x0_torch.requires_grad)\n",
    "\n",
    "# Calcul du prix\n",
    "price_grad = price_mc(x0_torch)\n",
    "print(\"price_grad.requires_grad :\", price_grad.requires_grad, \"\\n\")\n",
    "\n",
    "# Calcul du gradient du prix\n",
    "price_grad.backward()\n",
    "\n",
    "# Affichage du gradient par du prix par x0\n",
    "print(x0_torch.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradien = torch.autograd.grad(price_grad, x0_torch, create_graph=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Donne \"None\", ce qui n'est pas bon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_grad(x:float = 100.) :\n",
    "    x0_torch = torch.tensor([x0], requires_grad = True)\n",
    "    price_grad = price_mc(x0_torch)\n",
    "    price_grad.backward()\n",
    "    return x0_torch.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_grad(90.))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
